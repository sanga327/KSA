{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 웹의 이해\n",
    "### - 웹의 개념\n",
    "- 월드 와이드 웹(world wide web)은 인터넷에 연결된 컴퓨터를 이용하여 사람들과 정보를 공유할 수 있도록 거미줄처럼 엮인 공간\n",
    "- 월드 와이드 웹을 줄여 웹(web)이라고 한다. \n",
    "\n",
    "### - 웹 컴포넌트: HTML과 HTTP: HTML\n",
    "- HTML: 웹상의 정보를 구조적으로 표현하기 위한 언어\n",
    "- 태그(tag)는 꺽쇠 괄호 <>로 둘러싸여 있고, 그 안에 정보에 대한 의미를 적는다. 그리고 그 의미가 끝나는 부분에 슬래시(/)를 사용하여 해당 태그를 종료한다. \n",
    "\n",
    "### - 웹 컴포넌트: HTML과 HTTP: HTTP\n",
    "- HTTP는 인터넷에서 컴퓨터 간에 정보를 주고받을 때 사용하는 일종의 약속을 말하며, 일반적으로 컴퓨터 과학에서는 이러한 약속을 프로토콜이라고 한다. \n",
    "\n",
    "## 2. HTML 데이터 다루기\n",
    "### - 웹에서 데이터 다운로드하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14-1. html.py\n",
    "\n",
    "import urllib.request\n",
    "url = \"http://storage.googleapis.com/patents/grant_full_text/2014/ipg140107.zip\"\n",
    "\n",
    "print(\"Start Download\")\n",
    "fname, header = urllib.request.urlretrieve(url, 'ipg140107.zip')  \n",
    "# urlretrieve(URL 주소, 다운로드할 파일명)\n",
    "\n",
    "print(\"End Download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 정규 표현식\n",
    "### - 정규 표현식의 개념\n",
    "- 정규 표현식(regular expression)은 일종의 문자를 표현하는 공식으로, 특정 규칙이 있는 문자열 집합을 추출할 때 자주 사용하는 기법\n",
    "  \n",
    "### - 정규 표현식 문법: 기본 메타문자 []\n",
    "- 대괄호 []는 [와 ] 사이의 문자와 매칭하라는 뜻으로 사용된다. \n",
    "     ex) [abc]: 어떤 텍스트에 a 또는 b 또는 c 라는 텍스트가 있는지 찾으라는 뜻이다. \n",
    "     ex) 'Yesterday' 또는 'yesterday'라는 단어를 한 번에 찾으려면 [Yy]esterday라고 입력\n",
    "- 알파벳 전체나 한글 전체 텍스트를 찾고 싶다면 어떻게 하면 될까? \n",
    "    - '-'을 사용한다. [A-Za-z]나 [가-힝]과 같은 기호로 문자열에서 알파벳과 한글을 추출할 수 있다. \n",
    "    - 숫자 전체를 추출한다면 [0-9]로 쓸 수 있다.\n",
    "  \n",
    "### - 정규 표현식 문법: 반복 관련 메타문자 -, +, *, ?, {}\n",
    "  \n",
    "### - 정규 표현식 문법: 그 외 메타문자 (), ., |, ^, $, \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 웹 스크래핑 실습\n",
    "### - 아이디 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codo***\n",
      "outb7***\n",
      "dubba4***\n",
      "multicuspi***\n",
      "crownm***\n",
      "triformo***\n",
      "spania***\n",
      "magazin***\n",
      "presby***\n",
      "trophody***\n",
      "nontr***\n",
      "enranck***\n",
      "canc***\n",
      "uncanker***\n",
      "wrymo***\n",
      "non***\n",
      "luminat***\n",
      "oblig***\n",
      "anna***\n",
      "hyperth***\n",
      "toplabl***\n",
      "dolce0***\n",
      "rudals2***\n",
      "jjw980***\n",
      "elvlz***\n",
      "skmid***\n",
      "qkep***\n",
      "kisslov***\n",
      "maskman***\n",
      "sungt***\n"
     ]
    }
   ],
   "source": [
    "# 14-2.\n",
    "import re\n",
    "import urllib.request\n",
    "\n",
    "url = \"http://goo.gl/U7mSQl\"  # 접속할 웹 페이지\n",
    "html = urllib.request.urlopen(url)\n",
    "html_contents = str(html.read())\n",
    "id_results = re.findall(r\"([A-Za-z0-9]+\\*\\*\\*)\", html_contents) # findall 전체 찾기, 정규 표현식 패턴대로 데이터 찾기\n",
    "\n",
    "for result in id_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 파일 자동 다운로드\n",
    "- 파일을 자동으로 다운로드하는 Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "\n",
    "url = \"http://www.google.com/googlebooks/uspto-patents-grants-text.html\"  # url값 입력\n",
    "html = urllib.request.urlopen(url)\n",
    "html_contents = str(html.read().decode(\"utf8\"))  #html 파일 읽고 문자열로 변환\n",
    "\n",
    "url_list = re.findall(r\"(http)(.+)(zip)\", html_contents) # html 파일 읽고 문자열로 변환\n",
    "\n",
    "for url in url_list: \n",
    "    full_url =\"\".join(url)\n",
    "    print(full_url)\n",
    "    \n",
    "    fname, header = urllib.request.urlretrieve(full_url, file_name)\n",
    "    print(\"End Download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14-4.\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "url = \"http://finance.naver.com/item/main.nhn?code=005930\"\n",
    "html = urllib.request.urlopen(url)\n",
    "html_contents = str(html.read().decode(\"ms949\"))\n",
    "\n",
    "# 첫 번째 HTML 패턴\n",
    "stock_results = re.findall(\"(\\<dl class=\\\"blind\\\"\\>)([s\\S]+?)(\\<\\/dl\\>)\", html_contents)\n",
    "samsung_stock = stock_results[0]\n",
    "samsung_index = samsung_stock[1]\n",
    "\n",
    "# 주식 정보만 추출\n",
    "index_list = re.findall(\"(\\<dd\\>)([\\s\\S]+?)<\\<\\/dd\\>), samsung_index\")\n",
    "\n",
    "for index in index_list:\n",
    "    print(index[1])   # 세 개의 튜플 값 중 두 번째 값"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
