# 웨이블릿 변환

### 1. 웨이블릿 변환의 개념

- 웨이블릿은 기본 함수로 sine, cosine 함수 외에 웨이블릿 모함수를 사용하는데, 각 주파수 영역에 따라 변화하는 다양한 기저 함수를 생성하여 사용한다. 
- 푸리에 변환은 시간과 주파수 정보를 동시에 파악할 수 없지만 웨이블릿 변환에서는 둘 다 동시에 파악 가능

<br>

#### 1) 필터 뱅크를 이용한 이산 웨이블릿 변환

- 이산 웨이블릿 변환은 저주파 통과 필터와 고주파 통과 필터로 구성된 필터 뱅크로 수행된다.
- 이 때 사용되는 필터는 특수하게 설계된 것으로, 직교 특성, 선형 특성, 고주파와 저주파 부분을 정확하게 분할하는 특성이 있다. 

<img src = "https://github.com/sanga327/KSA/tree/main/Module05.%20%EC%98%81%EC%83%81%EC%B2%98%EB%A6%AC/Wavelet_Transform/Document/img/09_img/image-20210527112152018.png">

<br>

- 필터 뱅크의 동작을 이용한 웨이블릿 변환과 역변환의 수행 과정을 나타낸 것. 필터링은 컨벌루션으로 수행된다.
- 웨이블릿 변환 과정에서는 각각 필터링한 뒤 데이터의 크기를 절반으로 줄이는 다운샘플링이 수행되고, 웨이블릿 역변환 과정에서는 각각 필터링한 뒤 데이터의 크기를 원 상태로 보상해주려고 두 배로 증가시키는 업샘플링이 수행된다.

<img src = "https://github.com/sanga327/KSA/blob/main/Module05. 영상처리/Wavelet_Transform/Document/img/09_img/image-20210527112323774.png">

- 웨이블릿을 영상에 적용하려면 2차원 처리를 수행해야 한다. 
- 분리성을 만족한다. 
- 먼저 세로 방향으로 웨이블릿을 수행한 뒤 가로 방향으로 웨이블릿을 수행하면 2차원 웨이블릿 변환이 가능하다. 

<img src = "https://github.com/sanga327/KSA/blob/main/Module05. 영상처리/Wavelet_Transform/Document/img/09_img/image-20210527112421772.png">

<br>

---

# 웨이블릿 변환 실습

>**순방향 웨이블릿 변환**
>
>**역방향 웨이블릿 변환**

<br>

- **Class**:  WaveletTransformDoc.cpp, WaveletTransformView.cpp, CWaveletTransformDlg.cpp, CArrangeDlg.cpp
- **Function**: 
  - **순방향 웨이블릿 변환**: OnWaveletTransform, OnWaveletEncode, OnFilterTapGen, OnDownSampling, OnConvolution, OnMem2DAllocUnsigned, OnMem2DAllocDouble, OnScale 
  - **역방향 웨이블릿 변환**: OnWaveletDecode, OnUpSampling, OnSNR

<br>

---



#### 1) 순방향 웨이블릿 변환

- function

```c++
void CWaveletTransformDoc::OnWaveletEncode()
{
	// Wavelet encode 함수
	if (m_Level <= 0 || (pow(2, m_Level + 3) > (double)m_Width) || (pow(2, m_Level + 3) > (double)m_Height)) {
		AfxMessageBox(L"Not support decomposition level");
		return;
		// 최대 분해 레벨이 512*512이면 6레벨로 제한
	}

	int i, j, k, width, height;
	double *m_Conv1 = nullptr, *m_Conv2, *m_Conv3, *m_Conv4;  // Convolution을 위한 버퍼
	double *m_Down1 = nullptr, *m_Down2, *m_Down3, *m_Down4;  // 다운 샘플링을 위한 버퍼
	double *m_Hor = nullptr, *m_Ver1, *m_Ver2;
	double **m_L = nullptr, **m_H = nullptr, **m_LL = nullptr, **m_LH = nullptr, **m_HL = nullptr, **m_HH = nullptr, **m_SLL = nullptr, **m_SLH = nullptr, **m_SHL = nullptr, **m_SHH = nullptr;

	m_tempInput = OnMem2DAllocDouble(m_Height, m_Width);
	m_tempOutput = OnMem2DAllocDouble(m_Height, m_Width);
	m_ArrangeImage = OnMem2DAllocUnsigned(m_Height, m_Width);

	for (i = 0; i < m_Height; i++) {
		for (j = 0; j < m_Width; j++) {
			m_tempInput[i][j] = (double)m_InputImage[i* m_Width + j]; // 1차원 입력을 2차원 배열로 변환
		}
	}

	OnFilterTapGen(); // 필터 tap 생성

	m_FilterH0 = new double[m_FilterTap]; // 필터 계수를 위한 배열
	m_FilterH1 = new double[m_FilterTap]; // 필터 계수를 위한 배열
	m_FilterG0 = new double[m_FilterTap]; // 필터 계수를 위한 배열
	m_FilterG1 = new double[m_FilterTap]; // 필터 계수를 위한 배열

	OnFilterGen(m_FilterH0, m_FilterH1, m_FilterG0, m_FilterG1);  // 필터 계수 생성

	width = m_Width;
	height = m_Height;

	for (k = 0; k < m_Level; k++) {
		m_L = OnMem2DAllocDouble(height, width / 2); //
		m_H = OnMem2DAllocDouble(height, width / 2); //
		m_LL = OnMem2DAllocDouble(height / 2, width / 2); // LL 저장을 위한 배열
		m_LH = OnMem2DAllocDouble(height / 2, width / 2); // LH 저장을 위한 배열
		m_HL = OnMem2DAllocDouble(height / 2, width / 2); // HL 저장을 위한 배열
		m_HH = OnMem2DAllocDouble(height / 2, width / 2); // HH 저장을 위한 배열

		m_Hor = new double[width]; // 횡 입력을 위한 배열
		for (i = 0; i < height; i++) {
			for (j = 0; j < width; j++) {
				m_Hor[j] = m_tempInput[i][j]; // 입력 배열을 1차원 배열에 할당
			}

			m_Conv1 = OnConvolution(m_Hor, m_FilterH0, width, 1); // Convolution 처리
			m_Conv2 = OnConvolution(m_Hor, m_FilterH1, width, 1); // Convolution 처리
			m_Down1 = OnDownSampling(m_Conv1, width); // 다운 샘플링
			m_Down2 = OnDownSampling(m_Conv2, width); // 다운 샘플링

			for (j = 0; j < width / 2; j++) { // 다운 샘플링 결과를 저장
				m_L[i][j] = m_Down1[j];
				m_H[i][j] = m_Down2[j];
			}
		}

		m_Ver1 = new double[height];
		m_Ver2 = new double[height];

		for (i = 0; i < width / 2; i++) {
			for (j = 0; j < height; j++) {
				m_Ver1[j] = m_L[j][i]; // 열 방향으로 1차원 배열에 할당
				m_Ver2[j] = m_H[j][i];
			}

			m_Conv1 = OnConvolution(m_Ver1, m_FilterH0, height, 1);
			// Convolution 처리
			m_Conv2 = OnConvolution(m_Ver1, m_FilterH1, height, 1);
			m_Conv3 = OnConvolution(m_Ver2, m_FilterH0, height, 1);
			m_Conv4 = OnConvolution(m_Ver2, m_FilterH1, height, 1);

			m_Down1 = OnDownSampling(m_Conv1, height); // 다운 샘플링
			m_Down2 = OnDownSampling(m_Conv2, height);
			m_Down3 = OnDownSampling(m_Conv3, height);
			m_Down4 = OnDownSampling(m_Conv4, height);

			for (j = 0; j < height / 2; j++) {
				m_LL[j][i] = m_Down1[j]; // 결과 저장
				m_LH[j][i] = m_Down2[j];
				m_HL[j][i] = m_Down3[j];
				m_HH[j][i] = m_Down4[j];
			}
		}
		m_SLL = OnScale(m_LL, height / 2, width / 2); // 처리 결과를 정규화
		m_SLH = OnScale(m_LH, height / 2, width / 2);
		m_SHL = OnScale(m_HL, height / 2, width / 2);
		m_SHH = OnScale(m_HH, height / 2, width / 2);

		for (i = 0; i < height / 2; i++) {
			for (j = 0; j < width / 2; j++) {
				m_tempOutput[i][j] = m_LL[i][j];
				m_tempOutput[i][j + (width / 2)] = m_HL[i][j];
				m_tempOutput[i + (height / 2)][j] = m_LH[i][j];
				m_tempOutput[i + (height / 2)][j + (width / 2)] = m_HH[i][j];
				// 처리 결과를 정렬
				m_ArrangeImage[i][j] = (unsigned char)m_SLL[i][j];
				m_ArrangeImage[i][j + (width / 2)] = (unsigned char)m_SHL[i][j];
				m_ArrangeImage[i + (height / 2)][j] = (unsigned char)m_SLH[i][j];
				m_ArrangeImage[i + (height / 2)][j + (width / 2)] = (unsigned char)m_SHH[i][j];
				// 정규화 과정을 거친 정렬 영상
			}
		}
		width = width / 2; // 분해를 계속하기 위해 영상의 가로축 크기를 반으로 줄임
		height = height / 2; // 분해를 계속하기 위해 영상의 세로축 크기를 반으로 줄임
		m_tempInput = OnMem2DAllocDouble(height, width);

		for (i = 0; i < height; i++) {
			for (j = 0; j < width; j++) {
				m_tempInput[i][j] = m_LL[i][j]; // LL 값을 새로운 입력으로 할당
			}
		}
	}

	delete[] m_Conv1, m_Conv2, m_Conv3, m_Conv4;
	delete[] m_Down1, m_Down2, m_Down3, m_Down4;
	delete[] m_Hor, m_Ver1, m_Ver2;
    
	for (i = 0; i < height; i++) { // 메모리 해제
		delete[] m_LL[i];
		delete[] m_LH[i];
		delete[] m_HL[i];
		delete[] m_HH[i];
		delete[] m_SLL[i];
		delete[] m_SLH[i];
		delete[] m_SHL[i];
		delete[] m_SHH[i];
		delete[] m_L[i];
		delete[] m_H[i];
	}
	delete m_L, m_H, m_LL, m_LH, m_HL, m_HH, m_SLL, m_SLH,
		m_SHL, m_SHH;
	UpdateAllViews(NULL);
}
```

<br>

#### 2) 역방향 웨이블릿 변환 

- function

```c++
void CWaveletTransformDoc::OnWaveletDecode()
{
	int i, j, k;
	int width, height;
	double *tempLL = nullptr, *tempLH, *tempHL, *tempHH, *tempL, *tempH;
	double **L = nullptr, **H = nullptr;
	double *Up1 = nullptr, *Up2, *Up3, *Up4;
	double *Conv1 = nullptr, *Conv2, *Conv3, *Conv4;
	double **R = nullptr;

	width = m_Width / (int)(pow(2, m_Level));
	height = m_Height / (int)(pow(2, m_Level));

	m_Recon = new double[m_Width * m_Height];

	for (k = m_Level; k > 0; k--) {
		if (width > m_Width || height > m_Height) { // 분해 종료
			return;
		}

		tempLL = new double[height];
		tempLH = new double[height];
		tempHL = new double[height];
		tempHH = new double[height];

		L = OnMem2DAllocDouble(height * 2, width);
		H = OnMem2DAllocDouble(height * 2, width);

		tempL = new double[width];
		tempH = new double[width];

		R = OnMem2DAllocDouble(height * 2, width * 2);

		for (i = 0; i < width; i++) {
			for (j = 0; j < height; j++) {  // 정렬 영상에서 처리하려는 열을 분리
				tempLL[j] = m_tempOutput[j][i];
				tempLH[j] = m_tempOutput[j + height][i];
				tempHL[j] = m_tempOutput[j][i + width];
				tempHH[j] = m_tempOutput[j + height][i + width];
			}

			Up1 = OnUpSampling(tempLL, height); // 업 샘플링
			Up2 = OnUpSampling(tempLH, height);
			Up3 = OnUpSampling(tempHL, height);
			Up4 = OnUpSampling(tempHH, height);

			Conv1 = OnConvolution(Up1, m_FilterG0, height * 2, 2);
			// 컨벌루션 연산
			Conv2 = OnConvolution(Up2, m_FilterG1, height * 2, 2);
			Conv3 = OnConvolution(Up3, m_FilterG0, height * 2, 2);
			Conv4 = OnConvolution(Up4, m_FilterG1, height * 2, 2);

			for (j = 0; j < height * 2; j++) {
				L[j][i] = Conv1[j] + Conv2[j];
				H[j][i] = Conv3[j] + Conv4[j];
			}
		}
		for (i = 0; i < height * 2; i++) {
			for (j = 0; j < width; j++) {
				tempL[j] = L[i][j]; // 횡 데이터 분리
				tempH[j] = H[i][j];
			}

			Up1 = OnUpSampling(tempL, width); // 업 샘플링
			Up2 = OnUpSampling(tempH, width);

			Conv1 = OnConvolution(Up1, m_FilterG0, width * 2, 2);
			// 컨벌루션 연산
			Conv2 = OnConvolution(Up2, m_FilterG1, width * 2, 2);
			for (j = 0; j < width * 2; j++) {
				R[i][j] = Conv1[j] + Conv2[j];
			}
		}

		for (i = 0; i < height * 2; i++) {
			for (j = 0; j < width * 2; j++) {
				m_tempOutput[i][j] = R[i][j];  // 복원 데이터를 다시 정렬
			}
		}
		height = height * 2; // 영상의 크기를 두 배 확장
		width = width * 2;
	}

	for (i = 0; i < m_Height; i++) {
		for (j = 0; j < m_Width; j++) {
			m_Recon[i*   m_Width + j] = R[i][j];
			m_OutputImage[i*   m_Width + j] = (unsigned char)R[i][j];  // 최종 복원된 결과를 출력
		}
	}

	UpdateAllViews(NULL);

	delete[] tempLL, tempLH, tempHL, tempHH, tempL, tempH; // 메모리 해제
	delete[] Up1, Up2, Up3, Up4;
	delete[] Conv1, Conv2, Conv3, Conv4;

	for (i = 0; i < m_Height; i++) { // 메모리 해제
		delete[] L[i];
		delete[] H[i];
		delete[] R[i];
	}
	delete L, H, R;
}
```

<br>

- 실행 결과

<img src = "https://github.com/sanga327/KSA/blob/main/Module05. 영상처리/Wavelet_Transform/Document/img/09_img/image-20210529205348580.png">

<br>

- 3단계 분해된 영상

<img src = "https://github.com/sanga327/KSA/blob/main/Module05. 영상처리/Wavelet_Transform/Document/img/09_img/image-20210529205406801.png">

<br>

- 입력 영상과 복원 영상

<img src = "https://github.com/sanga327/KSA/blob/main/Module05. 영상처리/Wavelet_Transform/Document/img/image-20210529205424945.png">

